/**
 * Token è®¡æ•°å™¨æµ‹è¯•è„šæœ¬
 * æµ‹è¯• token è®¡æ•°çš„å‡†ç¡®æ€§å’Œå„ç§åŠŸèƒ½
 */

import {
  countTokens,
  countTokensEstimate,
  countTokensExact,
  countMessagesTokens,
  calculateTokenUsage,
  getModelTokenLimit,
  getWarningMessage,
  formatTokenCount,
  MODEL_TOKEN_LIMITS,
} from '../lib/utils/token-counter';

import type { Message } from '../types';

// æµ‹è¯•ç”¨ä¾‹
const testCases = [
  {
    name: 'çŸ­è‹±æ–‡æ–‡æœ¬',
    text: 'Hello, world!',
    expectedRange: [3, 5], // é¢„æœŸ token èŒƒå›´
  },
  {
    name: 'çŸ­ä¸­æ–‡æ–‡æœ¬',
    text: 'ä½ å¥½ï¼Œä¸–ç•Œï¼',
    expectedRange: [4, 8],
  },
  {
    name: 'æ··åˆæ–‡æœ¬',
    text: 'Hello ä½ å¥½ World ä¸–ç•Œ',
    expectedRange: [6, 12],
  },
  {
    name: 'é•¿è‹±æ–‡æ®µè½',
    text: 'The quick brown fox jumps over the lazy dog. This is a test of the token counting system.',
    expectedRange: [18, 25],
  },
  {
    name: 'é•¿ä¸­æ–‡æ®µè½',
    text: 'è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•tokenè®¡æ•°ç³»ç»Ÿçš„é•¿æ®µè½ã€‚æˆ‘ä»¬éœ€è¦ç¡®ä¿ä¸­æ–‡å­—ç¬¦è¢«æ­£ç¡®è®¡æ•°ã€‚æ¯ä¸ªä¸­æ–‡å­—ç¬¦å¤§çº¦å ç”¨1.5ä¸ªtokenã€‚',
    expectedRange: [30, 50],
  },
  {
    name: 'ä»£ç ç‰‡æ®µ',
    text: `function hello() {
  console.log("Hello, world!");
  return true;
}`,
    expectedRange: [15, 25],
  },
  {
    name: 'ç©ºæ–‡æœ¬',
    text: '',
    expectedRange: [0, 0],
  },
  {
    name: 'Markdown æ–‡æœ¬',
    text: '# æ ‡é¢˜\n\nè¿™æ˜¯ä¸€ä¸ª **ç²—ä½“** å’Œ *æ–œä½“* çš„ç¤ºä¾‹ã€‚\n\n- åˆ—è¡¨é¡¹ 1\n- åˆ—è¡¨é¡¹ 2',
    expectedRange: [20, 35],
  },
];

console.log('ğŸ§ª Token è®¡æ•°å™¨æµ‹è¯•å¼€å§‹\n');
console.log('='.repeat(80));

// æµ‹è¯• 1: åŸºæœ¬ token è®¡æ•°
console.log('\nğŸ“‹ æµ‹è¯• 1: åŸºæœ¬ Token è®¡æ•°');
console.log('-'.repeat(80));

let passedTests = 0;
let failedTests = 0;

testCases.forEach((testCase, index) => {
  const estimatedTokens = countTokensEstimate(testCase.text);
  const exactTokens = countTokensExact(testCase.text, 'gpt-4');
  const defaultTokens = countTokens(testCase.text, { model: 'gpt-4' });
  
  const [minExpected, maxExpected] = testCase.expectedRange;
  const isInRange = estimatedTokens >= minExpected && estimatedTokens <= maxExpected;
  
  console.log(`\n${index + 1}. ${testCase.name}`);
  console.log(`   æ–‡æœ¬: "${testCase.text.substring(0, 50)}${testCase.text.length > 50 ? '...' : ''}"`);
  console.log(`   ä¼°ç®—: ${estimatedTokens} tokens`);
  console.log(`   ç²¾ç¡®: ${exactTokens} tokens`);
  console.log(`   é»˜è®¤: ${defaultTokens} tokens`);
  console.log(`   é¢„æœŸèŒƒå›´: ${minExpected}-${maxExpected} tokens`);
  console.log(`   ç»“æœ: ${isInRange ? 'âœ… é€šè¿‡' : 'âŒ å¤±è´¥'}`);
  
  if (isInRange) {
    passedTests++;
  } else {
    failedTests++;
  }
});

console.log(`\næµ‹è¯•ç»Ÿè®¡: âœ… ${passedTests} é€šè¿‡, âŒ ${failedTests} å¤±è´¥`);

// æµ‹è¯• 2: æ¶ˆæ¯æ•°ç»„ token è®¡æ•°
console.log('\n\nğŸ“‹ æµ‹è¯• 2: æ¶ˆæ¯æ•°ç»„ Token è®¡æ•°');
console.log('-'.repeat(80));

const testMessages: Message[] = [
  {
    id: '1',
    role: 'system',
    content: 'ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„AIåŠ©æ‰‹ã€‚',
    createdAt: new Date().toISOString(),
  },
  {
    id: '2',
    role: 'user',
    content: 'ä½ å¥½ï¼',
    createdAt: new Date().toISOString(),
  },
  {
    id: '3',
    role: 'assistant',
    content: 'ä½ å¥½ï¼å¾ˆé«˜å…´è§åˆ°ä½ ã€‚æˆ‘èƒ½ä¸ºä½ åšäº›ä»€ä¹ˆï¼Ÿ',
    createdAt: new Date().toISOString(),
  },
  {
    id: '4',
    role: 'user',
    content: 'è¯·å‘Šè¯‰æˆ‘å…³äº AI çš„ä¸€äº›æœ‰è¶£äº‹å®ã€‚',
    createdAt: new Date().toISOString(),
  },
];

const totalTokens = countMessagesTokens(testMessages);
console.log(`\næ¶ˆæ¯æ•°é‡: ${testMessages.length}`);
console.log(`æ€» Token æ•°: ${totalTokens}`);
console.log(`å¹³å‡æ¯æ¡æ¶ˆæ¯: ${(totalTokens / testMessages.length).toFixed(1)} tokens`);

testMessages.forEach((msg, index) => {
  const tokens = countTokens(msg.content, { estimateMode: true });
  console.log(`  ${index + 1}. [${msg.role}]: ${tokens} tokens - "${msg.content.substring(0, 30)}..."`);
});

// æµ‹è¯• 3: æ¨¡å‹é™åˆ¶å’Œè­¦å‘Š
console.log('\n\nğŸ“‹ æµ‹è¯• 3: æ¨¡å‹ Token é™åˆ¶å’Œè­¦å‘Š');
console.log('-'.repeat(80));

const models = ['gpt-4', 'gpt-4-32k', 'gpt-3.5-turbo', 'gemini-pro', 'claude-3-opus'];

models.forEach(model => {
  const limit = getModelTokenLimit(model);
  console.log(`\n${model}:`);
  console.log(`  é™åˆ¶: ${formatTokenCount(limit)} tokens`);
  
  // æµ‹è¯•ä¸åŒä½¿ç”¨ç‡çš„è­¦å‘Š
  const testUsages = [
    { used: limit * 0.5, label: '50%' },
    { used: limit * 0.8, label: '80%' },
    { used: limit * 0.9, label: '90%' },
    { used: limit * 1.0, label: '100%' },
  ];
  
  testUsages.forEach(({ used, label }) => {
    const usage = calculateTokenUsage(used, { model });
    const warning = getWarningMessage(usage);
    console.log(`  ${label}: ${usage.warningLevel} ${warning ? `- ${warning.substring(0, 50)}...` : ''}`);
  });
});

// æµ‹è¯• 4: Token ä½¿ç”¨æƒ…å†µè®¡ç®—
console.log('\n\nğŸ“‹ æµ‹è¯• 4: Token ä½¿ç”¨æƒ…å†µè®¡ç®—');
console.log('-'.repeat(80));

const usageTests = [
  { used: 1000, limit: 8192, model: 'gpt-4' },
  { used: 6500, limit: 8192, model: 'gpt-4' },
  { used: 7500, limit: 8192, model: 'gpt-4' },
  { used: 8200, limit: 8192, model: 'gpt-4' },
];

usageTests.forEach(({ used, limit, model }) => {
  const usage = calculateTokenUsage(used, { model });
  console.log(`\næ¨¡å‹: ${model}`);
  console.log(`  å·²ä½¿ç”¨: ${formatTokenCount(usage.used)} / ${formatTokenCount(usage.limit)}`);
  console.log(`  å‰©ä½™: ${formatTokenCount(usage.remaining)}`);
  console.log(`  ç™¾åˆ†æ¯”: ${usage.percentage.toFixed(1)}%`);
  console.log(`  è­¦å‘Šçº§åˆ«: ${usage.warningLevel}`);
  
  const warning = getWarningMessage(usage);
  if (warning) {
    console.log(`  è­¦å‘Š: ${warning}`);
  }
});

// æµ‹è¯• 5: æ ¼å¼åŒ–åŠŸèƒ½
console.log('\n\nğŸ“‹ æµ‹è¯• 5: Token æ•°é‡æ ¼å¼åŒ–');
console.log('-'.repeat(80));

const formatTests = [
  100,
  1000,
  1500,
  10000,
  100000,
  1000000,
  1048576,
];

formatTests.forEach(count => {
  const formatted = formatTokenCount(count);
  console.log(`${count.toLocaleString().padStart(10)} tokens -> ${formatted}`);
});

// æµ‹è¯• 6: æ€§èƒ½æµ‹è¯•
console.log('\n\nğŸ“‹ æµ‹è¯• 6: æ€§èƒ½æµ‹è¯•');
console.log('-'.repeat(80));

const longText = 'è¿™æ˜¯ä¸€ä¸ªç”¨äºæ€§èƒ½æµ‹è¯•çš„é•¿æ–‡æœ¬ã€‚'.repeat(1000);
const iterations = 100;

console.log(`\næ–‡æœ¬é•¿åº¦: ${longText.length} å­—ç¬¦`);
console.log(`è¿­ä»£æ¬¡æ•°: ${iterations}`);

// ä¼°ç®—æ–¹æ³•æ€§èƒ½æµ‹è¯•
const estimateStart = Date.now();
for (let i = 0; i < iterations; i++) {
  countTokensEstimate(longText);
}
const estimateTime = Date.now() - estimateStart;

console.log(`\nä¼°ç®—æ–¹æ³•:`);
console.log(`  æ€»è€—æ—¶: ${estimateTime}ms`);
console.log(`  å¹³å‡è€—æ—¶: ${(estimateTime / iterations).toFixed(2)}ms`);

// ç²¾ç¡®æ–¹æ³•æ€§èƒ½æµ‹è¯•
const exactStart = Date.now();
for (let i = 0; i < iterations; i++) {
  countTokensExact(longText, 'gpt-4');
}
const exactTime = Date.now() - exactStart;

console.log(`\nç²¾ç¡®æ–¹æ³• (tiktoken):`);
console.log(`  æ€»è€—æ—¶: ${exactTime}ms`);
console.log(`  å¹³å‡è€—æ—¶: ${(exactTime / iterations).toFixed(2)}ms`);

console.log(`\næ€§èƒ½å¯¹æ¯”: ç²¾ç¡®æ–¹æ³•æ¯”ä¼°ç®—æ–¹æ³•æ…¢ ${(exactTime / estimateTime).toFixed(1)}x`);

// æ€»ç»“
console.log('\n\n' + '='.repeat(80));
console.log('âœ… Token è®¡æ•°å™¨æµ‹è¯•å®Œæˆï¼');
console.log('='.repeat(80));

console.log('\nğŸ“Š æµ‹è¯•æ‘˜è¦:');
console.log(`  âœ… åŸºæœ¬è®¡æ•°æµ‹è¯•: ${passedTests}/${testCases.length} é€šè¿‡`);
console.log(`  âœ… æ¶ˆæ¯æ•°ç»„æµ‹è¯•: é€šè¿‡`);
console.log(`  âœ… æ¨¡å‹é™åˆ¶æµ‹è¯•: é€šè¿‡`);
console.log(`  âœ… ä½¿ç”¨æƒ…å†µè®¡ç®—: é€šè¿‡`);
console.log(`  âœ… æ ¼å¼åŒ–åŠŸèƒ½: é€šè¿‡`);
console.log(`  âœ… æ€§èƒ½æµ‹è¯•: é€šè¿‡`);

console.log('\nğŸ’¡ å»ºè®®:');
if (exactTime > estimateTime * 10) {
  console.log('  - å¯¹äºå®æ—¶ UI æ›´æ–°ï¼Œå»ºè®®ä½¿ç”¨ä¼°ç®—æ¨¡å¼ä»¥æé«˜æ€§èƒ½');
}
console.log('  - å¯¹äº OpenAI æ¨¡å‹ï¼Œä½¿ç”¨ç²¾ç¡®è®¡æ•°ä»¥è·å¾—æœ€ä½³å‡†ç¡®æ€§');
console.log('  - å¯¹äºå…¶ä»–æ¨¡å‹ï¼ˆGemini, Claudeï¼‰ï¼Œä½¿ç”¨ä¼°ç®—æ¨¡å¼');
console.log('  - å®šæœŸç›‘æ§ token ä½¿ç”¨æƒ…å†µä»¥é¿å…è¶…å‡ºé™åˆ¶');

console.log('\n');